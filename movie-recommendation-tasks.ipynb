{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":77759,"sourceType":"datasetVersion","datasetId":339}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"02b036f0-b07f-44c0-bc43-51946a29d432","cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:49:35.710338Z","iopub.execute_input":"2025-06-18T11:49:35.710567Z","iopub.status.idle":"2025-06-18T11:49:35.995700Z","shell.execute_reply.started":"2025-06-18T11:49:35.710550Z","shell.execute_reply":"2025-06-18T11:49:35.994921Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/movielens-20m-dataset/rating.csv\n/kaggle/input/movielens-20m-dataset/link.csv\n/kaggle/input/movielens-20m-dataset/genome_tags.csv\n/kaggle/input/movielens-20m-dataset/genome_scores.csv\n/kaggle/input/movielens-20m-dataset/tag.csv\n/kaggle/input/movielens-20m-dataset/movie.csv\n","output_type":"stream"}],"execution_count":1},{"id":"dad07985-20fc-4fd9-91d0-79ed25a4ae2b","cell_type":"code","source":"\nimport pandas as pd \nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:49:35.997432Z","iopub.execute_input":"2025-06-18T11:49:35.997812Z","iopub.status.idle":"2025-06-18T11:49:40.664941Z","shell.execute_reply.started":"2025-06-18T11:49:35.997792Z","shell.execute_reply":"2025-06-18T11:49:40.664397Z"}},"outputs":[],"execution_count":2},{"id":"1fec6861-56ad-4681-b85c-0cd30780dec2","cell_type":"code","source":"\nos.environ['TORCH'] = torch.__version__\n\n# !pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n# !pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n# !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n# !pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n!pip install torch_geometric pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-${TORCH}.html\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:49:40.665634Z","iopub.execute_input":"2025-06-18T11:49:40.665996Z","iopub.status.idle":"2025-06-18T11:49:50.503681Z","shell.execute_reply.started":"2025-06-18T11:49:40.665977Z","shell.execute_reply":"2025-06-18T11:49:50.502974Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\nCollecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyg_lib\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch_scatter\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch_sparse\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting torch_cluster\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hCollecting torch_spline_conv\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.18)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_geometric, torch_cluster\nSuccessfully installed pyg_lib-0.4.0+pt26cu124 torch_cluster-1.6.3+pt26cu124 torch_geometric-2.6.1 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124 torch_spline_conv-1.2.2+pt26cu124\n","output_type":"stream"}],"execution_count":3},{"id":"f8ed4874-1068-4826-af7e-52a058d7d421","cell_type":"code","source":"from  torch_geometric.nn import GCNConv,SAGEConv,GATConv,HeteroConv\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.data import Data,HeteroData","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:49:50.504674Z","iopub.execute_input":"2025-06-18T11:49:50.504918Z","iopub.status.idle":"2025-06-18T11:49:55.998625Z","shell.execute_reply.started":"2025-06-18T11:49:50.504885Z","shell.execute_reply":"2025-06-18T11:49:55.997882Z"}},"outputs":[],"execution_count":4},{"id":"1692b5f7-a038-446c-9922-68cd40ab1861","cell_type":"code","source":"df_rating=pd.read_csv(\"/kaggle/input/movielens-20m-dataset/rating.csv\")\ndf_movie=pd.read_csv(\"/kaggle/input/movielens-20m-dataset/movie.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:49:55.999490Z","iopub.execute_input":"2025-06-18T11:49:56.000323Z","iopub.status.idle":"2025-06-18T11:50:16.040342Z","shell.execute_reply.started":"2025-06-18T11:49:56.000293Z","shell.execute_reply":"2025-06-18T11:50:16.039547Z"}},"outputs":[],"execution_count":5},{"id":"5e937cbe-b3af-4e8e-aa77-9a112f3fc5eb","cell_type":"code","source":"df_movie.head(-1)\n\ndf_movie['movieId'].unique\n\ndf_movie['movieId'].\n\ndf_rating['userId'].shape\n\ndf_rating['userId'].unique\n\n\ndf_rating['movieId'].nunique\n\ndf_rating.head()\n\ndf_rating.isnull().sum()\n\ndf_rating.duplicated().sum()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:50:16.041125Z","iopub.execute_input":"2025-06-18T11:50:16.041388Z","iopub.status.idle":"2025-06-18T11:50:16.048483Z","shell.execute_reply.started":"2025-06-18T11:50:16.041365Z","shell.execute_reply":"2025-06-18T11:50:16.046465Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_35/761601829.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    df_movie['movieId'].\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (761601829.py, line 5)","output_type":"error"}],"execution_count":6},{"id":"628e5cfc-e710-4287-8ef2-3b6713550f8f","cell_type":"code","source":"df_rating['userId']=df_rating['userId'].astype('category').cat.codes\ndf_rating['movieId']=df_rating['movieId'].astype('category').cat.codes\n\nnum_users=int(df_rating['userId'].nunique())\nnum_items=int(df_rating['movieId'].nunique())\n\nprint(\"NUM users:\",num_users)\nprint(\"num items: \",num_items)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:50:41.166785Z","iopub.execute_input":"2025-06-18T11:50:41.167336Z","iopub.status.idle":"2025-06-18T11:50:42.239082Z","shell.execute_reply.started":"2025-06-18T11:50:41.167312Z","shell.execute_reply":"2025-06-18T11:50:42.238223Z"}},"outputs":[{"name":"stdout","text":"NUM users: 138493\nnum items:  26744\n","output_type":"stream"}],"execution_count":7},{"id":"4b2c9559-5063-4891-8354-b182d9602c19","cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:50:44.741767Z","iopub.execute_input":"2025-06-18T11:50:44.742072Z","iopub.status.idle":"2025-06-18T11:50:44.746256Z","shell.execute_reply.started":"2025-06-18T11:50:44.742031Z","shell.execute_reply":"2025-06-18T11:50:44.745423Z"}},"outputs":[],"execution_count":8},{"id":"98578f61-c4c0-42db-830c-ddf58523bb74","cell_type":"code","source":"def create_graph(df_rating, df_movie):\n    # (a) Keep only movies that appear in the ratings\n    rated_ids = df_rating['movieId'].unique()\n    df_movie = df_movie[df_movie['movieId'].isin(rated_ids)].copy()\n    \n    # (b) Category‐encode userId and movieId (only rated movies)\n    df_rating['user_code']  = pd.Categorical(df_rating['userId']).codes\n    df_rating['movie_code'] = pd.Categorical(df_rating['movieId'], \n                                             categories=rated_ids).codes\n    num_users  = df_rating['user_code'].nunique()\n    num_movies = df_rating['movie_code'].nunique()\n    \n    # (c) Build genre‐one-hot matrix for exactly these movie_codes\n    # Map original movieId → code\n    movie_to_code = dict(zip(rated_ids, range(num_movies)))\n    df_movie['movie_code'] = df_movie['movieId'].map(movie_to_code)\n    \n    # Drop duplicates so each movie_code appears once with its genres\n    gm = ( df_movie[['movie_code','genres']]\n           .drop_duplicates('movie_code')\n           .set_index('movie_code')['genres']\n           .str.get_dummies(sep='|') )\n    # Reindex 0…num_movies-1, fill missing with all zeros\n    gm = gm.reindex(range(num_movies), fill_value=0)\n    movie_feats = torch.tensor(gm.values, dtype=torch.float)   # [num_movies, num_genres]\n    \n    # (d) Dummy user features (or you can plug in real ones)\n    user_feats = torch.arange(num_users, dtype=torch.float).view(-1,1)\n    \n    # (e) Build edge_index and edge_attr from df_rating\n    edge_index = torch.tensor([\n        df_rating['user_code'].values,\n        df_rating['movie_code'].values\n    ], dtype=torch.long)\n    edge_attr  = torch.tensor(df_rating['rating'].values, dtype=torch.float)\n    \n    # (f) Assemble HeteroData\n    graph = HeteroData()\n    graph['user'].x = user_feats\n    graph['movie'].x = movie_feats\n    graph['user','rates','movie'].edge_index = edge_index\n    graph['user','rates','movie'].edge_attr  = edge_attr\n    graph['movie','rated_by','user'].edge_index = edge_index[[1,0]]\n    \n    return graph\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:50:45.187122Z","iopub.execute_input":"2025-06-18T11:50:45.187436Z","iopub.status.idle":"2025-06-18T11:50:45.195787Z","shell.execute_reply.started":"2025-06-18T11:50:45.187414Z","shell.execute_reply":"2025-06-18T11:50:45.194938Z"}},"outputs":[],"execution_count":9},{"id":"81902ce8-6929-401b-b885-e46924e7cb8b","cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_data, test_data = train_test_split(df_rating, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:50:46.151640Z","iopub.execute_input":"2025-06-18T11:50:46.151910Z","iopub.status.idle":"2025-06-18T11:50:54.997939Z","shell.execute_reply.started":"2025-06-18T11:50:46.151891Z","shell.execute_reply":"2025-06-18T11:50:54.997354Z"}},"outputs":[],"execution_count":10},{"id":"17f6abbb-6cb9-4de2-8b2b-913aef1ecf53","cell_type":"code","source":"train_graph=create_graph(train_data,df_movie).to(device)\ntest_graph=create_graph(test_data,df_movie).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:50:54.998996Z","iopub.execute_input":"2025-06-18T11:50:54.999485Z","iopub.status.idle":"2025-06-18T11:51:03.887397Z","shell.execute_reply.started":"2025-06-18T11:50:54.999466Z","shell.execute_reply":"2025-06-18T11:51:03.886780Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1611852729.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n  edge_index = torch.tensor([\n","output_type":"stream"}],"execution_count":11},{"id":"a73db5ef-ab34-4d1c-8e25-50b34c830c7f","cell_type":"code","source":"train_graph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:51:03.888117Z","iopub.execute_input":"2025-06-18T11:51:03.888382Z","iopub.status.idle":"2025-06-18T11:51:03.895266Z","shell.execute_reply.started":"2025-06-18T11:51:03.888358Z","shell.execute_reply":"2025-06-18T11:51:03.894588Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"HeteroData(\n  user={ x=[138493, 1] },\n  movie={ x=[25827, 19] },\n  (user, rates, movie)={\n    edge_index=[2, 16000210],\n    edge_attr=[16000210],\n  },\n  (movie, rated_by, user)={ edge_index=[2, 16000210] }\n)"},"metadata":{}}],"execution_count":12},{"id":"2b3931c2-4b0f-4cfc-af2b-a6c8ffa95ccd","cell_type":"code","source":"\nprint(\"total user nodes\",train_graph['user'].x.shape[0])\nprint(\"total movies :\", train_graph['movie'].x.shape[0])\nprint(\" - user:\", train_graph['user', 'rates', 'movie'].edge_index[0].max().item())\nprint(\" - movie:\", train_graph['user', 'rates', 'movie'].edge_index[1].max().item())\nprint(\" - movie :\", train_graph['movie', 'rated_by', 'user'].edge_index[0].max().item())\nprint(\" - user:\", train_graph['movie', 'rated_by', 'user'].edge_index[1].max().item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:51:03.897176Z","iopub.execute_input":"2025-06-18T11:51:03.897385Z","iopub.status.idle":"2025-06-18T11:51:03.979231Z","shell.execute_reply.started":"2025-06-18T11:51:03.897369Z","shell.execute_reply":"2025-06-18T11:51:03.978409Z"}},"outputs":[{"name":"stdout","text":"total user nodes 138493\ntotal movies : 25827\n - user: 138492\n - movie: 25826\n - movie : 25826\n - user: 138492\n","output_type":"stream"}],"execution_count":13},{"id":"76653310-dccd-4ae8-a25e-aa66821e893f","cell_type":"code","source":"from torch_geometric.nn import MessagePassing\nimport torch.nn.functional as F\nfrom torch_scatter import scatter_softmax\nfrom torch.nn import Linear, ModuleDict, BatchNorm1d, Dropout\n\n\nclass AttAwareConv(MessagePassing):\n    def __init__(self):\n        super().__init__(aggr='add')\n        self.att=torch.nn.Linear(1,1)\n\n    def forward(self,x_user,x_movie,edge_index,edge_attr):\n\n        if edge_attr.dim()==1:\n            edge_attr=edge_attr.view(-1,1)\n        edge_attr=edge_attr.to(dtype=torch.float)\n        score=self.att(edge_attr)\n        score=score.squeeze(-1)\n        softmax_score=scatter_softmax(score,edge_index[1],dim=0)\n        self._edge_weight=softmax_score\n\n        return self.propagate(edge_index,x=(x_user,x_movie))\n\n    def message(self, x_j):\n        \"\"\"\n        x_j: source node features for each edge\n        self._edge_weight: attention score per edge\n        \"\"\"\n        return x_j * self._edge_weight.view(-1,1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:51:03.979910Z","iopub.execute_input":"2025-06-18T11:51:03.980164Z","iopub.status.idle":"2025-06-18T11:51:03.986292Z","shell.execute_reply.started":"2025-06-18T11:51:03.980140Z","shell.execute_reply":"2025-06-18T11:51:03.985437Z"}},"outputs":[],"execution_count":14},{"id":"a5be1079-b224-4ab9-ad33-14289bdf961e","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"75f254fb-3c46-4c63-b935-9f0dae272467","cell_type":"code","source":"class GNNEncoder(torch.nn.Module):\n    \n    def __init__(self,hidden_channels,output_channels):\n        \n        super().__init__()\n        self.lin_dict=ModuleDict({\n            'user':torch.nn.LazyLinear(hidden_channels),\n            'movie':torch.nn.LazyLinear(hidden_channels)\n        })\n\n        self.norm_dict=ModuleDict({\n        'user':BatchNorm1d(hidden_channels),\n        'movie':BatchNorm1d(hidden_channels)\n        })\n\n        self.drop=Dropout(0.2)\n\n        self.att_layer = AttAwareConv()  # Attention Layer\n        self.conv1 = HeteroConv({\n            ('user', 'rates', 'movie'): SAGEConv((-1, -1), hidden_channels),\n            ('movie', 'rated_by', 'user'): SAGEConv((-1, -1), hidden_channels),\n        }, aggr='mean')\n\n        self.conv2 = HeteroConv({\n            ('user', 'rates', 'movie'): SAGEConv((-1, -1), output_channels),\n            ('movie', 'rated_by', 'user'): SAGEConv((-1, -1), output_channels),\n        }, aggr='mean')\n\n        \n    def forward(self, x_dict, edge_index_dict, edge_attr_dict):\n        # Step 1: preprocess input features\n        x_dict = {key: self.lin_dict[key](x) for key, x in x_dict.items()}\n        x_dict = {key: self.norm_dict[key](x) for key, x in x_dict.items()}\n        x_dict = {key: self.drop(F.relu(x)) for key, x in x_dict.items()}\n\n        # Step 2: apply attention layer to user→movie edges\n        edge_index = edge_index_dict[('user','rates','movie')]\n        edge_attr = edge_attr_dict[('user','rates','movie')]\n        #print(\"type:\",type(edge_attr))\n        att_out = self.att_layer(x_dict['user'], x_dict['movie'], edge_index, edge_attr)\n        \n        # Update movie features with attention-weighted user messages\n        x_dict['movie'] = x_dict['movie'] + att_out\n\n        # Step 3: apply graph convolutions\n        x_dict = self.conv1(x_dict, {('user','rates','movie'): edge_index,\n                                 ('movie','rated_by','user'): edge_index[[1, 0]]})\n        x_dict = {key: self.drop(F.relu(x)) for key, x in x_dict.items()}\n        x_dict = self.conv2(x_dict, {('user','rates','movie'): edge_index,\n                                 ('movie','rated_by','user'): edge_index[[1, 0]]})\n\n        return x_dict\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:51:03.987115Z","iopub.execute_input":"2025-06-18T11:51:03.987355Z","iopub.status.idle":"2025-06-18T11:51:04.005175Z","shell.execute_reply.started":"2025-06-18T11:51:03.987331Z","shell.execute_reply":"2025-06-18T11:51:04.004556Z"}},"outputs":[],"execution_count":15},{"id":"20c1e5b1-68c9-4fb6-a272-d27a292b985d","cell_type":"code","source":"class EdgeDecoder(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        self.mlp = torch.nn.Sequential(\n            Linear(2 * hidden_channels, 4 * hidden_channels),\n            torch.nn.ReLU(),\n            Dropout(0.2),\n            Linear(4 * hidden_channels, 2 * hidden_channels),\n            torch.nn.ReLU(),\n            Linear(2 * hidden_channels, 1)\n        )\n\n    def forward(self, z_dict, edge_label_index):\n        user_z = z_dict['user'][edge_label_index[0]]\n        movie_z = z_dict['movie'][edge_label_index[1]]\n        features = torch.cat([user_z, movie_z], dim=-1)\n        return self.mlp(features).squeeze(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:51:04.005788Z","iopub.execute_input":"2025-06-18T11:51:04.006057Z","iopub.status.idle":"2025-06-18T11:51:04.024683Z","shell.execute_reply.started":"2025-06-18T11:51:04.006024Z","shell.execute_reply":"2025-06-18T11:51:04.023925Z"}},"outputs":[],"execution_count":16},{"id":"dd063913-0552-4dcd-8277-52ebc75d1db3","cell_type":"code","source":"class GNNRecommendationModel(torch.nn.Module):\n    def __init__(self, hidden_channels, metadata):\n        super().__init__()\n        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n        self.decoder = EdgeDecoder(hidden_channels)\n\n    def forward(self, x_dict, edge_index_dict, edge_label_index, edge_attr_dict):\n        z_dict = self.encoder(x_dict, edge_index_dict, edge_attr_dict)\n        return self.decoder(z_dict, edge_label_index)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:51:04.025454Z","iopub.execute_input":"2025-06-18T11:51:04.025737Z","iopub.status.idle":"2025-06-18T11:51:04.041772Z","shell.execute_reply.started":"2025-06-18T11:51:04.025721Z","shell.execute_reply":"2025-06-18T11:51:04.041078Z"}},"outputs":[],"execution_count":17},{"id":"4dde1fd2-8e73-43f1-8f33-f82eb9510632","cell_type":"code","source":"model=GNNRecommendationModel(hidden_channels=64,metadata=train_graph.metadata()).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\ncriterion = torch.nn.MSELoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:51:04.042524Z","iopub.execute_input":"2025-06-18T11:51:04.042728Z","iopub.status.idle":"2025-06-18T11:51:04.100958Z","shell.execute_reply.started":"2025-06-18T11:51:04.042714Z","shell.execute_reply":"2025-06-18T11:51:04.100408Z"}},"outputs":[],"execution_count":18},{"id":"4607d0b6-858e-493c-bdf2-f0f9c8817150","cell_type":"code","source":"from torch_geometric.loader import LinkNeighborLoader\n\ndef prepare_loaders(train_graph, test_graph, batch_size=256):\n    \n    train_loader = LinkNeighborLoader(\n        data=train_graph,\n        num_neighbors=[10, 5],\n        edge_label_index=(('user', 'rates', 'movie'), train_graph[('user', 'rates', 'movie')].edge_index),\n        edge_label=train_graph[('user', 'rates', 'movie')].edge_attr,  \n        batch_size=batch_size,\n        shuffle=True,\n    )\n  \n    test_loader = LinkNeighborLoader(\n        data=test_graph,\n        num_neighbors=[10, 5],\n        edge_label_index=(('user', 'rates', 'movie'), test_graph[('user', 'rates', 'movie')].edge_index),\n        edge_label=test_graph[('user', 'rates', 'movie')].edge_attr,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    \n    return train_loader, test_loader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:51:04.102514Z","iopub.execute_input":"2025-06-18T11:51:04.102726Z","iopub.status.idle":"2025-06-18T11:51:04.107714Z","shell.execute_reply.started":"2025-06-18T11:51:04.102710Z","shell.execute_reply":"2025-06-18T11:51:04.106926Z"}},"outputs":[],"execution_count":19},{"id":"02508644-44f7-4ff0-b123-a4d744fc0de8","cell_type":"code","source":"train_loader, test_loader = prepare_loaders(train_graph, test_graph, batch_size=256)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:51:04.108485Z","iopub.execute_input":"2025-06-18T11:51:04.108694Z","iopub.status.idle":"2025-06-18T11:51:05.193471Z","shell.execute_reply.started":"2025-06-18T11:51:04.108679Z","shell.execute_reply":"2025-06-18T11:51:05.192807Z"}},"outputs":[],"execution_count":20},{"id":"28281b8f-39fb-42c7-a9ca-bed41ef2b21b","cell_type":"code","source":"def train_epoch():\n    model.train(); total=0\n    for batch in train_loader:\n        batch = batch.to(device)\n        ea = {etype: batch[etype].edge_attr\n              for etype in batch.edge_types if 'edge_attr' in batch[etype]}\n        pred = model(batch.x_dict, batch.edge_index_dict,\n                     batch[('user','rates','movie')].edge_label_index, ea)\n        loss = F.mse_loss(pred, batch[('user','rates','movie')].edge_label)\n        optimizer.zero_grad(); loss.backward(); optimizer.step()\n        total += loss.item()*pred.size(0)\n    return total/len(train_loader.dataset)\n\ndef eval_epoch(loader):\n    model.eval(); tot=0\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            ea = {etype: batch[etype].edge_attr\n                  for etype in batch.edge_types if 'edge_attr' in batch[etype]}\n            pred = model(batch.x_dict, batch.edge_index_dict,\n                         batch[('user','rates','movie')].edge_label_index, ea)\n            tot += F.mse_loss(pred, batch[('user','rates','movie')].edge_label,\n                              reduction='sum').item()\n    rmse = (tot/len(loader.dataset))**0.5\n    return rmse\n\nfor epoch in range(1, 5):\n    train_loss = train_epoch()\n    test_metrics = eval_epoch(test_loader)\n    \n    scheduler.step()\n    \n    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, '\n          f'Test RMSE: {test_metrics:.4f}')\n    \n\ntorch.save(model.state_dict(), 'movie_recommender.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T12:42:40.338850Z","iopub.execute_input":"2025-06-18T12:42:40.339163Z","execution_failed":"2025-06-18T16:37:35.574Z"}},"outputs":[{"name":"stdout","text":"Epoch: 001, Train Loss: 1.1069, Test RMSE: 1.0521\nEpoch: 002, Train Loss: 1.1069, Test RMSE: 1.0521\nEpoch: 003, Train Loss: 1.1069, Test RMSE: 1.0521\n","output_type":"stream"}],"execution_count":null},{"id":"7232e018-82b8-40a0-9322-5deefc4af7ba","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e72259f1-14e6-4637-ad2c-8391ce86a58e","cell_type":"code","source":"\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ea69f923","cell_type":"code","source":"\ndef generate_recommendations(model, data, user_id, top_k=10, device='cpu'):\n   \n    model.eval()\n    data = data.to(device)\n    \n    with torch.no_grad():\n        \n        z_dict = model.encoder(data.x_dict, data.edge_index_dict)\n        \n\n        if isinstance(user_id, int):\n            user_id = torch.tensor([user_id], device=device)\n        \n        user_emb = z_dict['user'][user_id]  # shape: [1, emb_dim]\n        movie_emb = z_dict['movie']         # shape: [num_movies, emb_dim]\n        \n        edge_label_index = torch.stack([\n            user_id.repeat(movie_emb.size(0)),\n            torch.arange(movie_emb.size(0), device=device)\n        ])\n        scores = model.decoder(z_dict, edge_label_index)  # shape: [num_movies]\n        \n        rated_mask = torch.zeros(movie_emb.size(0), dtype=torch.bool, device=device)\n        user_edges = (data['user', 'rates', 'movie'].edge_index[0] == user_id)\n        rated_movies = data['user', 'rates', 'movie'].edge_index[1][user_edges]\n        rated_mask[rated_movies] = True\n        scores[rated_mask] = -float('inf')\n        \n        top_scores, top_movies = torch.topk(scores, k=min(top_k, len(scores)))\n        \n        return top_movies.cpu().numpy(), top_scores.cpu().numpy()\n\n\nid_list,score_list = generate_recommendations(model, train_graph, 50,device=device)\n\nmovie_titles = movies['title'].to_dict()\n\n\nfor i in range(10):\n    original_id = id_list[i]\n    print(f\"{i+1}. {movie_titles.get(original_id)}  score:{score_list[i]:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T11:50:16.072645Z","iopub.status.idle":"2025-06-18T11:50:16.073020Z","shell.execute_reply.started":"2025-06-18T11:50:16.072908Z","shell.execute_reply":"2025-06-18T11:50:16.072923Z"}},"outputs":[],"execution_count":null}]}